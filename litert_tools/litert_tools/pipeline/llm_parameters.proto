// Copyright 2023 The ODML Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package litert_tools.pipeline;

// Prompt template to be used for prefill and decode calls.
// Here is an example of the template based on Gemma's specifications here:
// https://ai.google.dev/gemma/docs/formatting
//
//  message prepended {
//    .prompt_prefix = "<start_of_turn>user\n ";
//    .prompt_suffix = "<end_of_turn>\n<start_of_turn>model\n";
//  }
//
message PromptTemplate {
  reserved 1;

  // Text prepended to the input prompt on the first chunck of the prefill call.
  // This is useful for adding start of user's turn markers.
  string prompt_prefix = 2;

  // Text appended to the input prompt upon transition to decode. This is useful
  // for adding start of model of model's turn markers.
  string prompt_suffix = 3;
}

// A collection of prompt templates for different roles.
// Here is an example of the template based on Gemma's specifications here:
// https://ai.google.dev/gemma/docs/formatting
//
//  message prompt_templates {
//    .user_template = {
//      .prompt_prefix = "<start_of_turn>user\n";
//      .prompt_suffix = "<end_of_turn>\n";
//    }
//  }
//
message PromptTemplates {
  // The template for user role.
  optional PromptTemplate user_template = 1;

  reserved 2, 3;
}

// Subset of parameters for Large Language Models (LLM) that are used to define
// the prompt template.
message LlmParameters {
  reserved 1, 2, 3;

  // Start token prepended to the beginning of input sequence.
  oneof start_token_union {
    int32 start_token_id = 4;
    string start_token = 6;
  }

  // Stop tokens to determine the end of output stream.
  repeated string stop_tokens = 5;

  reserved 7;

  PromptTemplate prompt_template = 8 [deprecated = true];

  reserved 9, 10, 11, 12, 13, 14, 15, 16;

  // Prompt templates for different roles.
  optional PromptTemplates prompt_templates = 17;
}

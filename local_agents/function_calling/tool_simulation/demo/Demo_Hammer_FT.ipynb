{
  "cells": [
    {
      "metadata": {
        "id": "Ymv9OfKES4Ec"
      },
      "cell_type": "code",
      "source": [
        "!pip install trl\n",
        "!pip install peft"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cS9ByI_AFEhp"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "dmfJqaigFYnn"
      },
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"MadeAgents/Hammer2.1-0.5b\"\n",
        "ADAPTER_SAVE_PATH = \"/tmp/hammer_lora\"\n",
        "RESULTS_OUTPUT_DIR = \"/tmp/results_lora\"\n",
        "TRAIN_DATA_PATH = \"train.json\"\n",
        "VAL_DATA_PATH = \"val.json\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "x8bAx-CgWFTX"
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(ADAPTER_SAVE_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_OUTPUT_DIR, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "0LSPoIxCWPwA"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Loading tokenizer for {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dpoQP91WTeW",
        "outputId": "da9957c2-2957-4ba3-9843-7c6da362364e"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Loading model for {MODEL_NAME}...\")\n",
        "\n",
        "MODEL_PRECISION = torch.float16\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=MODEL_PRECISION\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model for MadeAgents/Hammer2.1-0.5b...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "7c-of3DhWmCB"
      },
      "cell_type": "code",
      "source": [
        "target_modules_qwen2 = [\n",
        "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "    \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "]\n",
        "print(\"\\nModel modules (first few layers for brevity):\")\n",
        "module_names = set(name for name, _ in model.named_modules())\n",
        "\n",
        "valid_target_modules = [m for m in target_modules_qwen2 if any(m in name for name in module_names)]\n",
        "\n",
        "print(f\"Using LoRA target modules: {valid_target_modules}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "j6mZs7NJWsoj"
      },
      "cell_type": "code",
      "source": [
        "# Since this is just for a demo, we haven't experimented with these hparams.\n",
        "# Set them as you see fit.\n",
        "peft_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=valid_target_modules,\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(\"\\nLoRA configured. Trainable parameters:\")\n",
        "model.print_trainable_parameters()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "aCl4TLKMWuhl"
      },
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "with open(TRAIN_DATA_PATH, \"r\") as file:\n",
        "    data = json.load(file)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "YNynsaE_bC4t"
      },
      "cell_type": "code",
      "source": [
        "eval_data = []\n",
        "with open(VAL_DATA_PATH, \"r\") as file:\n",
        "    data = json.load(file)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "OY8UokplbJ48"
      },
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_list(train_data)\n",
        "eval_dataset = Dataset.from_list(eval_data)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "k_I0wLnabKlO"
      },
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "  {\n",
        "    \"description\": \"Records the user's personal information.\",\n",
        "    \"name\": \"record_personal_information\",\n",
        "    \"parameters\": {\n",
        "      \"properties\": {\n",
        "        \"first_name\": {\n",
        "          \"description\": \"The user's first name.\",\n",
        "          \"type\": \"STRING\"\n",
        "        },\n",
        "        \"last_name\": {\n",
        "          \"description\": \"The user's last name.\",\n",
        "          \"type\": \"STRING\"\n",
        "        },\n",
        "        \"date_of_birth\": {\n",
        "          \"description\": \"The user's date of birth in MM/DD/YYYY format.\",\n",
        "          \"type\": \"STRING\"\n",
        "        },\n",
        "        \"occupation\": {\n",
        "          \"description\": \"The user's occupation.\",\n",
        "          \"type\": \"STRING\"\n",
        "        }\n",
        "      },\n",
        "      \"required\": [\n",
        "        \"first_name\",\n",
        "        \"last_name\",\n",
        "        \"date_of_birth\",\n",
        "        \"occupation\"\n",
        "      ],\n",
        "      \"type\": \"OBJECT\"\n",
        "    }\n",
        "  },\n",
        "  {\n",
        "    \"description\": \"Records the user's sex and marital status.\",\n",
        "    \"name\": \"record_demographics\",\n",
        "    \"parameters\": {\n",
        "      \"properties\": {\n",
        "        \"sex\": {\n",
        "          \"description\": \"The user's sex.\",\n",
        "          \"enum\": [\n",
        "            \"Female\",\n",
        "            \"Male\"\n",
        "          ],\n",
        "          \"type\": \"STRING\"\n",
        "        },\n",
        "        \"marital_status\": {\n",
        "          \"description\": \"The user's marital status.\",\n",
        "          \"enum\": [\n",
        "            \"Single\",\n",
        "            \"Partnered\",\n",
        "            \"Married\",\n",
        "            \"Separated\",\n",
        "            \"Divorced\",\n",
        "            \"Widowed\"\n",
        "          ],\n",
        "          \"type\": \"STRING\"\n",
        "        }\n",
        "      },\n",
        "      \"required\": [\n",
        "        \"sex\",\n",
        "        \"marital_status\"\n",
        "      ],\n",
        "      \"type\": \"OBJECT\"\n",
        "    }\n",
        "  },\n",
        "  {\n",
        "    \"description\": \"Records the user's past or present medical history conditions.\",\n",
        "    \"name\": \"record_medical_history\",\n",
        "    \"parameters\": {\n",
        "      \"properties\": {\n",
        "        \"conditions\": {\n",
        "          \"description\": \"A list of medical conditions the user checks.\",\n",
        "          \"items\": {\n",
        "            \"enum\": [\n",
        "              \"Kidney Disease\",\n",
        "              \"Liver Disease\",\n",
        "              \"Blood Clots\",\n",
        "              \"Anemia\",\n",
        "              \"Arthritis\",\n",
        "              \"Asthma\",\n",
        "              \"High Blood Pressure\",\n",
        "              \"Psychiatric Disorder\",\n",
        "              \"Heart Murmur\",\n",
        "              \"High Cholesterol\",\n",
        "              \"Migraines\",\n",
        "              \"Diabetes\"\n",
        "            ],\n",
        "            \"type\": \"STRING\"\n",
        "          },\n",
        "          \"type\": \"ARRAY\"\n",
        "        }\n",
        "      },\n",
        "      \"required\": [\n",
        "        \"conditions\"\n",
        "      ],\n",
        "      \"type\": \"OBJECT\"\n",
        "    }\n",
        "  }\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "lh3x8QcfbMUK"
      },
      "cell_type": "code",
      "source": [
        "IGNORE_INDEX = -100\n",
        "\n",
        "def pad_tensor(tensor, target_length, pad_value):\n",
        "    current_length = tensor.size(0)\n",
        "    if current_length \u003e= target_length:\n",
        "        print(\"TRUNCATING\")\n",
        "        return tensor[:target_length]\n",
        "    else:\n",
        "        padding = torch.full(\n",
        "            (target_length - current_length,),\n",
        "            pad_value,\n",
        "            dtype=tensor.dtype,\n",
        "            device=tensor.device\n",
        "        )\n",
        "        return torch.cat((tensor, padding), dim=0)\n",
        "\n",
        "def apply_template_and_mask_labels(examples):\n",
        "    all_input_ids = []\n",
        "    all_attention_mask = []\n",
        "    all_labels = []\n",
        "\n",
        "    for conversation_messages in examples[\"messages\"]:\n",
        "        full_templated_text = tokenizer.apply_chat_template(\n",
        "            conversation_messages,\n",
        "            tokenize=False,\n",
        "            tools=tools,\n",
        "            add_generation_prompt=True\n",
        "            # Somehow regardless of add_generation_promp=True/False the suffix\n",
        "            # is always added. As a workaround we always add it and then remove it.\n",
        "        )[:-len(\"\u003c|im_start|\u003eassistant\\n\")]\n",
        "        tokenized_output = tokenizer(\n",
        "            full_templated_text,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length = 1024\n",
        "        )\n",
        "        input_ids = tokenized_output[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = tokenized_output[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        assistant_tag_str = \"\u003c|im_start|\u003eassistant\\n\"\n",
        "\n",
        "        last_assistant_tag_char_idx = full_templated_text.rfind(assistant_tag_str)\n",
        "        if last_assistant_tag_char_idx == -1:\n",
        "            labels[:] = IGNORE_INDEX\n",
        "        else:\n",
        "            prompt_part_text = full_templated_text[:last_assistant_tag_char_idx]\n",
        "            prompt_tokens_ids = tokenizer(prompt_part_text, add_special_tokens=True).input_ids\n",
        "            token_index_to_mask_up_to = len(prompt_tokens_ids)\n",
        "\n",
        "            labels[:token_index_to_mask_up_to] = IGNORE_INDEX\n",
        "\n",
        "        input_ids_padded = pad_tensor(input_ids, 1024, tokenizer.pad_token_id)\n",
        "        attention_mask_padded = pad_tensor(attention_mask, 1024, 0)\n",
        "        labels_padded = pad_tensor(labels, 1024, IGNORE_INDEX)\n",
        "\n",
        "        all_input_ids.append(input_ids_padded.tolist())\n",
        "        all_attention_mask.append(attention_mask_padded.tolist())\n",
        "        all_labels.append(labels_padded.tolist())\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": all_input_ids,\n",
        "        \"attention_mask\": all_attention_mask,\n",
        "        \"labels\": all_labels,\n",
        "    }\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(apply_template_and_mask_labels, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(apply_template_and_mask_labels, batched=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "VAI-McINbca7"
      },
      "cell_type": "code",
      "source": [
        "# Since this is just for a demo, we haven't experimented with these hparams.\n",
        "# Set them as you see fit.\n",
        "sft_config = SFTConfig(\n",
        "    output_dir=RESULTS_OUTPUT_DIR,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"adamw_torch\",\n",
        "    learning_rate=2e-5,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.03,\n",
        "    logging_steps=25,\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True,\n",
        "    max_seq_length=1024,\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "tVrIzRIPcSJC"
      },
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=sft_config,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        ")\n",
        "print(\"\\nSFTTrainer configured.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "x_ykup10cXsf"
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nStarting training...\")\n",
        "trainer.train()\n",
        "print(\"Training completed.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "hfTp_NryhQq1"
      },
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

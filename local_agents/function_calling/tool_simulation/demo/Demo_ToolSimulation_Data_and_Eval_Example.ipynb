{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f3b9ebafad248118b64cf23dce0a61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32741f06e5084d8798c2224efcd7c3cf",
              "IPY_MODEL_5887704c80884c929e8d372089a011cb",
              "IPY_MODEL_11dab0cfc62e4f6581d3780e75d7447e"
            ],
            "layout": "IPY_MODEL_416a1915b7e74c47b11d03e285f6a4ae"
          }
        },
        "32741f06e5084d8798c2224efcd7c3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33dc3183d5dc40ef82b6f127beb287fb",
            "placeholder": "​",
            "style": "IPY_MODEL_b5184142a28a419f9050e22242d4a933",
            "value": "config.json: 100%"
          }
        },
        "5887704c80884c929e8d372089a011cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb4245441924896891f1632bbf6f629",
            "max": 913,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_141064ef626c41aba3d7e078eaf4fa6f",
            "value": 913
          }
        },
        "11dab0cfc62e4f6581d3780e75d7447e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1634a1925df243928b753fab773df957",
            "placeholder": "​",
            "style": "IPY_MODEL_656370ea54dc4dd2b4b89ffcfde3a19e",
            "value": " 913/913 [00:00&lt;00:00, 89.6kB/s]"
          }
        },
        "416a1915b7e74c47b11d03e285f6a4ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33dc3183d5dc40ef82b6f127beb287fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5184142a28a419f9050e22242d4a933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb4245441924896891f1632bbf6f629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141064ef626c41aba3d7e078eaf4fa6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1634a1925df243928b753fab773df957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656370ea54dc4dd2b4b89ffcfde3a19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9705736d66a842169404503244eded5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f7a15d398a04e59a42be6ea9fc1fcdf",
              "IPY_MODEL_eda94e4151bb4d53bfcfaf972a81eca6",
              "IPY_MODEL_3507a8b9c00a41e4a807e59e7c9785a5"
            ],
            "layout": "IPY_MODEL_315f57be19534156ba0b01022de1e124"
          }
        },
        "7f7a15d398a04e59a42be6ea9fc1fcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_391cfc87c42c4cb48dab62ebb8629430",
            "placeholder": "​",
            "style": "IPY_MODEL_474db1b9a1124c07969b50691c6bdad8",
            "value": "model.safetensors: 100%"
          }
        },
        "eda94e4151bb4d53bfcfaf972a81eca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9e005a9f6504e118431a504262e9551",
            "max": 3086634632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8845ec543d5249aabb95ceb477f7f33f",
            "value": 3086634632
          }
        },
        "3507a8b9c00a41e4a807e59e7c9785a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d8961b88c741a8910c259971e28ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_537741f1deed45fcb8d8a4a2224b645f",
            "value": " 3.09G/3.09G [00:30&lt;00:00, 168MB/s]"
          }
        },
        "315f57be19534156ba0b01022de1e124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391cfc87c42c4cb48dab62ebb8629430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474db1b9a1124c07969b50691c6bdad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9e005a9f6504e118431a504262e9551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8845ec543d5249aabb95ceb477f7f33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23d8961b88c741a8910c259971e28ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537741f1deed45fcb8d8a4a2224b645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a4596dca9e84673ab2c982f872fc422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87db057a86c542d4a4c1a9578368a1ce",
              "IPY_MODEL_f01de8ddf7b44acc810dcab31b1c871e",
              "IPY_MODEL_2b242a2d6b684bb1a5b035bde30e41f3"
            ],
            "layout": "IPY_MODEL_1fd1b745e97a40e49ee4d809f5fb06a3"
          }
        },
        "87db057a86c542d4a4c1a9578368a1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70488af18eed468091b06c207b4365ba",
            "placeholder": "​",
            "style": "IPY_MODEL_ac439360b04c4587b35e939930379243",
            "value": "generation_config.json: 100%"
          }
        },
        "f01de8ddf7b44acc810dcab31b1c871e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da13d9cabfbe4af58cdad42130a093f3",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a01ee1256dd643db9b353b3b07ae3f57",
            "value": 117
          }
        },
        "2b242a2d6b684bb1a5b035bde30e41f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab71243e360f4d65abd245ff88b457a9",
            "placeholder": "​",
            "style": "IPY_MODEL_4c510ca4f59641f59c469b829083789d",
            "value": " 117/117 [00:00&lt;00:00, 7.02kB/s]"
          }
        },
        "1fd1b745e97a40e49ee4d809f5fb06a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70488af18eed468091b06c207b4365ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac439360b04c4587b35e939930379243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da13d9cabfbe4af58cdad42130a093f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01ee1256dd643db9b353b3b07ae3f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab71243e360f4d65abd245ff88b457a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c510ca4f59641f59c469b829083789d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Data and Eval Example\n",
        "\n",
        "In this colab we showcase how to use the `tool_simulation` library in order to create a finetuning dataset or evaluate a given model.\n",
        "\n",
        "For our example we will create a dataset related to a healthcare app with an AI form filler feature. To do this, we will set up a few patient scenarios and use them to create covnersations with an agent.\n",
        "\n",
        "We will aslo show an example of how to evaluate a model that we've trained."
      ],
      "metadata": {
        "id": "D0FiE-ehwtG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn77s8V-0Hew"
      },
      "outputs": [],
      "source": [
        "!pip install ai-edge-tool-simulation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "from google.genai import types\n",
        "\n",
        "import tool_simulation.stages.utils.margin as margin\n",
        "from tool_simulation.core.aistudio_backend import AIStudioModel\n",
        "from tool_simulation.core.aistudio_prompt_builder import AIStudioPromptBuilder, ChunkKind\n",
        "from tool_simulation.core.tool2str import tool2str\n",
        "from tool_simulation.stages.data_generation import seed_data\n",
        "from tool_simulation.stages.function_calling.replier_prompt_builder import ReplierPromptBuilder\n",
        "from tool_simulation.core.str2call import FunctionCall\n",
        "from tool_simulation.stages.function_calling.session import SyntheticSession, FunctionReply\n",
        "from tool_simulation.stages.function_calling import datagen_prompt_builder\n",
        "from tool_simulation.stages.function_calling import function_calling_episode\n",
        "from tool_simulation.stages.exports.export_hf_chat import export_hf_chat\n"
      ],
      "metadata": {
        "id": "3yyEKp6H0wxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Data Generation\n",
        "Here we will genertate patient scenarios and use them to create conversations with an agent."
      ],
      "metadata": {
        "id": "CVwRNg-YxqYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"YOUR_API_KEY\"\n",
        "MODEL = \"gemini-2.5-flash-preview-04-17\"\n",
        "# How many examples to use when genearting scenarios\n",
        "SUBSAMPLE_SIZE = 3\n",
        "# How many scenario generation steps to make\n",
        "SIMULATION_STEPS = 5"
      ],
      "metadata": {
        "id": "FDCPqL5I5mr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario Generation\n",
        "We will create a set of sample scenarios and iteratievely generate more by taking a sample from our existing pool as a set of examples."
      ],
      "metadata": {
        "id": "sX6Kiolrx0zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _scenario_prompt(example_str: str) -> str:\n",
        "  return margin.trim_margin(f\"\"\"\\\n",
        "    |Your job is to generate patient scenarios. We are trying to model a\n",
        "    >health intake form.\n",
        "    |Please generate short patient scenarios/biographies that include things\n",
        "    >like name, birth date, health issues, job, marital status, but also\n",
        "    >general bipgraphical places like city of birth, favorite\n",
        "    >stuff, activity levels etc.\n",
        "    |The scenarios should be formatted in plain text and be in the first person.\n",
        "    |Please vary the sentence structure and syntax when generating everything.\n",
        "    |Here are a few examples (dont forget the <END> tags after each scenario):\n",
        "    |\n",
        "    |{example_str}\n",
        "    |\n",
        "    |Please generate 3 to 5 new scenarios in the above\n",
        "    >format (but dont repeat them).\n",
        "    |List only the examples, do not add any other text or ennumeration.\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "kVvoz-WD42Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We recommmend having soem seed data. For this demo we will generate some\n",
        "example_pool = []\n",
        "example_pool.append(\n",
        "    \"My name is John Doe, I am a car mechanic suffering from back pain. I\"\n",
        "    \" am married and I am 35. I am not super active.<END>\"\n",
        ")\n",
        "example_pool.append(\n",
        "    \"I'm Aisha Khan, a 18-year-old student dealing with anxiety. I am\"\n",
        "    \" currently single.<END>\"\n",
        ")\n",
        "example_pool.append(\n",
        "    \"Hi I am Kenji Tanaka. I work as a high school teacher and have type 2\"\n",
        "    \" diabetes. I'm 25 and divorced. I am from Toky originally.<END>\"\n",
        ")\n",
        "example_pool.append(\n",
        "    \"Call me Chloe Dubois. I'm a retired librarian, 68 years old, widowed,\"\n",
        "    \" and I manage my arthritis daily.<END>\"\n",
        ")"
      ],
      "metadata": {
        "id": "5e6zUhYQ45Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AIStudioModel(api_key=API_KEY, model_name=MODEL)"
      ],
      "metadata": {
        "id": "yeA04XRX5_7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(SIMULATION_STEPS):\n",
        "  try:\n",
        "    random.shuffle(example_pool)\n",
        "    examples = min(SUBSAMPLE_SIZE, len(example_pool))\n",
        "    example_str = \"\\n\".join(example_pool[:examples])\n",
        "    # We create a prompt builder object to hold the query\n",
        "    pb = AIStudioPromptBuilder()\n",
        "    pb.user_turn(_scenario_prompt(example_str))\n",
        "    # Generate seed data will query the model, split\n",
        "    # the reply by the <END> delimiter and filter empty queries\n",
        "    # as well as re-append the \"<END>\" token\n",
        "    extra_examples = seed_data.generate_seed_data(\n",
        "        pb,\n",
        "        model,\n",
        "        delimiter=\"<END>\",\n",
        "        filter_fn=lambda x: x.strip(),\n",
        "        post_process_fn=lambda x: x.strip()\n",
        "        .replace(\"\\n\", \"\")\n",
        "        .replace(\"<END>\", \"\")\n",
        "        + \"<END>\",\n",
        "    )\n",
        "    example_pool.extend(extra_examples)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break\n",
        "\n",
        "scenarios = [x.replace(\"<END>\", \"\") for x in example_pool]"
      ],
      "metadata": {
        "id": "-f1gNAZY4745"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Data Generation\n",
        "Now we can run the data generation loop. To start, we will define an API schema\n",
        "as well as a simple enviornment (for simplicity this will just give an OK signal). In addition we will define a parser function. For this example we will assume that the API we are calling does sufficient checks and returns a response in a structured form."
      ],
      "metadata": {
        "id": "0lkiD1_oyDbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "health_conditions_options = [\n",
        "  \"Hypertension\",\n",
        "  \"Diabetes\",\n",
        "  \"Asthma\",\n",
        "  \"Arthritis\",\n",
        "  \"Migraine\",\n",
        "  \"Depression\",\n",
        "  \"Kidney Disease\",\n",
        "  \"Anxiety\",\n",
        "  \"Allergies\",\n",
        "  \"Heart Disease\",\n",
        "]\n",
        "\n",
        "marital_status_options = [\"Single\",\"Married\",\"Divorced\",\n",
        "                              \"Widowed\",\"Separated\",\"Domestic Partnership\"]\n",
        "sex_options = [\"Male\", \"Female\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "my_demo_tool = types.Tool(\n",
        "    function_declarations=[\n",
        "        types.FunctionDeclaration(\n",
        "            name=\"record_personal_information\",\n",
        "            description=\"Records the user's personal information.\",\n",
        "            parameters=types.Schema(\n",
        "                type=types.Type.OBJECT,\n",
        "                properties={\n",
        "                    \"first_name\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=\"The user's first name.\",\n",
        "                    ),\n",
        "                    \"last_name\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=\"The user's last name.\",\n",
        "                    ),\n",
        "                    \"date_of_birth\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=(\n",
        "                            \"The user's date of birth in MM/DD/YYYY format.\"\n",
        "                        ),\n",
        "                    ),\n",
        "                    \"occupation\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=\"The user's occupation.\",\n",
        "                    ),\n",
        "                },\n",
        "                required=[\n",
        "                    \"first_name\",\n",
        "                    \"last_name\",\n",
        "                    \"date_of_birth\",\n",
        "                    \"occupation\",\n",
        "                ],\n",
        "            ),\n",
        "        ),\n",
        "        types.FunctionDeclaration(\n",
        "            name=\"record_demographics\",\n",
        "            description=\"Records the user's sex and marital status.\",\n",
        "            parameters=types.Schema(\n",
        "                type=types.Type.OBJECT,\n",
        "                properties={\n",
        "                    \"sex\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=\"The user's sex.\",\n",
        "                        enum=sex_options,\n",
        "                    ),\n",
        "                    \"marital_status\": types.Schema(\n",
        "                        type=types.Type.STRING,\n",
        "                        description=\"The user's marital status.\",\n",
        "                        enum=marital_status_options,\n",
        "                    ),\n",
        "                },\n",
        "                required=[\"sex\", \"marital_status\"],\n",
        "            ),\n",
        "        ),\n",
        "        types.FunctionDeclaration(\n",
        "            name=\"record_medical_history\",\n",
        "            description=(\n",
        "                \"Records the user's past or present medical history conditions.\"\n",
        "            ),\n",
        "            parameters=types.Schema(\n",
        "                type=types.Type.OBJECT,\n",
        "                properties={\n",
        "                    \"conditions\": types.Schema(\n",
        "                        type=types.Type.ARRAY,\n",
        "                        description=(\n",
        "                            \"A list of medical conditions the user checks.\"\n",
        "                        ),\n",
        "                        items=types.Schema(\n",
        "                            type=types.Type.STRING, enum=health_conditions_options\n",
        "                        ),\n",
        "                    )\n",
        "                },\n",
        "                required=[\"conditions\"],\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "1bPZJNca0kec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleEnvironment(SyntheticSession):\n",
        "  def reply(self, function_call: FunctionCall) -> FunctionReply:\n",
        "    function_call_unwrapped = json.loads(function_call.raw_string)\n",
        "    reply = {\"name\": function_call_unwrapped[\"name\"], \"response\": {\"status\": \"ok\"}}\n",
        "    return FunctionReply(reply = reply, raw_reply = json.dumps(reply))"
      ],
      "metadata": {
        "id": "4DiNgxbyZdTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_output(text: str) -> datagen_prompt_builder.ParseResult:\n",
        "  if not text:\n",
        "    return datagen_prompt_builder.ParseResult(function_call=None, forward=None)\n",
        "  try:\n",
        "    output_json = json.loads(text)\n",
        "    function_call = FunctionCall(name = output_json[\"name\"], args={}, raw_string=text)\n",
        "    return datagen_prompt_builder.ParseResult(function_call=function_call, forward=None)\n",
        "  except json.JSONDecodeError:\n",
        "    return datagen_prompt_builder.ParseResult(function_call=None, forward=text)"
      ],
      "metadata": {
        "id": "LF3VT-T8aRpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_loop(scenario: str):\n",
        "  # Make the replier model prompt. The replier model will pretend to be the human\n",
        "  replier_pbuilder = ReplierPromptBuilder()\n",
        "  replier_pbuilder.system_turn(margin.trim_margin(f\"\"\"\\\n",
        "      |You are using a mobile app with a voice feature attached to an agent. You\n",
        "      >want to fill out a healthcare intake form which has three screens.\n",
        "      |The screens are as follows:\n",
        "      |Screen 1: Asks for first and second name, date of birth, and occupation\n",
        "      |Screen 2: Asks for marital status ({\", \".join(marital_status_options)})\n",
        "      >and sex {\", \".join(sex_options)}\n",
        "      |Screen 3: Asks for health conditions ({\", \".join(health_conditions_options)})\n",
        "      |\n",
        "      |You are given the following patient scenario:\n",
        "      |{scenario}\n",
        "      |\n",
        "      |Please talk to the agent (you should go screen by screen). First you reply\n",
        "      >to the first srceen, wait for its reply, then you reply to the second, etc.\n",
        "      |Your messages are prefaced by the `User` role, while the agent's responses\n",
        "      >are prefaced by the `Assistant` role.\n",
        "      >If the agent is able to successfully complete the task, please\n",
        "      >reply with STOP. If it made an error, reply with ERROR.\n",
        "      |Do not ask the assistant any follow-up questions.\n",
        "      |When you return your reply, do not preface it with any role, that happens\n",
        "      >automatically.\n",
        "      |NOTE: Only give a single reply at a time, do not complete the entire\n",
        "      >conversation.\n",
        "      |NOTE: Give your replies in natural language only.\n",
        "      \"\"\"))\n",
        "  # Set models\n",
        "  replier_model = AIStudioModel(api_key=API_KEY, model_name=MODEL)\n",
        "  function_calling_model = AIStudioModel(api_key=API_KEY, model_name=MODEL, tools=my_demo_tool)\n",
        "  function_calling_model.config.system_instruction = \"Please help the user fill out an intake form. The user will give you some information and you need to call the correct functions. Only fill out what they have given you. You are only allowed to do function calls and summarize the result of the given function calls.\"\n",
        "\n",
        "  # Get a scenario -> intial query\n",
        "  initial_query = replier_model.query_model(replier_pbuilder.get_prompt())\n",
        "  initial_query = initial_query.replace(\"User:\", \"\").replace(\"User\", \"\").strip()\n",
        "  # Add the initial query to the user turn\n",
        "  replier_pbuilder.user_turn(initial_query)\n",
        "\n",
        "  # Create a prompt builder to represent the agent\n",
        "  inner_fc_pb = AIStudioPromptBuilder()\n",
        "  inner_fc_pb.user_turn(initial_query)\n",
        "  datagen_pbuilder = datagen_prompt_builder.DataGenerationPromptBuilder(\n",
        "    inner_prompt_builder=inner_fc_pb,\n",
        "    session=SimpleEnvironment(),\n",
        "    parse_fn=parse_output,\n",
        "  )\n",
        "  # Run episode\n",
        "  try:\n",
        "    result = function_calling_episode.run_function_calling_episode(\n",
        "          fc_prompt_builder=datagen_pbuilder,\n",
        "          replier_prompt_builder=replier_pbuilder,\n",
        "          function_calling_model=function_calling_model,\n",
        "          replier_model=replier_model,\n",
        "          max_steps=6,\n",
        "    )\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return []\n",
        "  #The below is formating the reply according to the hammer model's format.\n",
        "  hf_format = []\n",
        "  for turn in result.get_state():\n",
        "    for chunk in turn.content:\n",
        "      if chunk.kind == ChunkKind.CONTENT:\n",
        "        hf_format.append({\"role\": \"user\" if turn.role == \"user\" else \"assistant\",\n",
        "                          \"content\": chunk.content.text})\n",
        "      elif chunk.kind == ChunkKind.TOOL_CALL:\n",
        "        hf_format.append({\"role\": \"assistant\",\n",
        "                    \"content\": f\"```[{chunk.content.function_call.to_json_dict()}]```\"})\n",
        "      elif chunk.kind == ChunkKind.TOOL_RESULT:\n",
        "        hf_format.append({\"role\": \"tool\",\n",
        "              \"content\": f\"{chunk.content.function_response.to_json_dict()}\"})\n",
        "  return hf_format\n"
      ],
      "metadata": {
        "id": "Umvq5drdB8Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversations = []\n",
        "for scenario in scenarios:\n",
        "  conversation = run_loop(scenario)\n",
        "  if conversation:\n",
        "    conversations.append({\"messages\" : conversation})\n",
        "  print(\"Done with scenario \", scenario)"
      ],
      "metadata": {
        "id": "ioMEDrM5DQD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DgBA5B09ZvKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Evaluation\n",
        "\n",
        "For this demo we will evaluate the Hammer function calling models. The evalation loop will be simular, with the only differnece being a change in the\n",
        "tool calling model. While not shown above, we assume that we have a separate test set we can use in the case of model training. For simplicity we will be using the same set of scenarios as above."
      ],
      "metadata": {
        "id": "tuSQKX8Iy3er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    PreTrainedTokenizerBase,\n",
        "\n",
        ")\n",
        "\n",
        "from tool_simulation.core import base_prompt_builder\n",
        "from tool_simulation.core.tool2str import tool2str\n",
        "from tool_simulation.core.model_instance import ModelInstance"
      ],
      "metadata": {
        "id": "PHNaiskV1K6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will define a prompt builder that works with the huggingface chat format. We will use this to prompt the tool callling model. We will also define a ModelInstance that works with HuggingFace."
      ],
      "metadata": {
        "id": "eXRCf0B6z-c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Prompt builder for Hugging Face's chat template.\"\"\"\n",
        "\n",
        "BaseTurn = base_prompt_builder.BaseTurn\n",
        "ChunkKind = base_prompt_builder.ChunkKind\n",
        "BasePromptBuilder = base_prompt_builder.BasePromptBuilder\n",
        "BaseChunk = base_prompt_builder.BaseChunk\n",
        "\n",
        "\n",
        "class HfChunk(BaseChunk[str]):\n",
        "  \"\"\"A chunk of text in a Hugging Face prompt.\"\"\"\n",
        "\n",
        "  def __init__(self, content: str, kind: ChunkKind = ChunkKind.CONTENT):\n",
        "    super().__init__(content=content, kind=kind)\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "    return self.content\n",
        "\n",
        "\n",
        "class HfTurn(BaseTurn[HfChunk]):\n",
        "  \"\"\"A turn in a Hf prompt.\n",
        "\n",
        "  Since the hf format is List[Dict[str, str]] we dont enforce any particular\n",
        "  structure on the content. We use the abstraction already in the code but\n",
        "  mock the Hf format.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, role: str, content: Optional[List[HfChunk]] = None):\n",
        "    if content and len(content) > 1:\n",
        "      raise ValueError(\n",
        "          \"Multiple chunks in a turn are not supported in Hugging Face format.\"\n",
        "      )\n",
        "    super().__init__(role=role, content=content)\n",
        "\n",
        "  @property\n",
        "  def content(self) -> List[HfChunk]:\n",
        "    return list(self._content)\n",
        "\n",
        "  @content.setter\n",
        "  def content(self, value: List[HfChunk]) -> None:\n",
        "    if len(value) > 1:\n",
        "      raise ValueError(\n",
        "          \"Multiple chunks in a turn are not supported in Hugging Face format.\"\n",
        "      )\n",
        "    self._content = list(value)\n",
        "\n",
        "  def add_chunk(self, chunk: HfChunk) -> None:\n",
        "    if not isinstance(chunk, HfChunk):\n",
        "      raise TypeError(f\"Expected a HfChunk object, got {type(chunk)}\")\n",
        "    if len(self._content) >= 1:\n",
        "      raise ValueError(\n",
        "          \"Multiple chunks in a turn are not supported in Hugging Face format.\"\n",
        "      )\n",
        "    self._content.append(chunk)\n",
        "\n",
        "  @property\n",
        "  def inner_content(self) -> str:\n",
        "    if not self._content:\n",
        "      raise ValueError(\"Turn has no content.\")\n",
        "    return str(self._content[0].content)\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "    raise NotImplementedError(\"Prompts are generated via `get_prompt`.\")\n",
        "\n",
        "  def to_dict(self) -> Dict[str, str]:\n",
        "    return {\n",
        "        \"role\": self.role,\n",
        "        \"content\": self.inner_content,\n",
        "    }\n",
        "\n",
        "\n",
        "class HfChatPromptBuilder(BasePromptBuilder[HfChunk, HfTurn, str]):\n",
        "  \"\"\"Builds prompts compatible with Hugging Face's apply_chat_template.\n",
        "\n",
        "  Manages conversation history as a list of dictionaries suitable for\n",
        "  tokenizer.apply_chat_template.\n",
        "\n",
        "  The base prompt builder class is generic with respect to the\n",
        "  chunk/turn/content types. For this example we subclass it with the types we\n",
        "  define above. For simplicity the inner content type is str.\n",
        "  \"\"\"\n",
        "\n",
        "  _tokenizer: PreTrainedTokenizerBase\n",
        "  _tools: Optional[List[Dict[str, Any]]]\n",
        "\n",
        "  _USER_ROLE = \"user\"\n",
        "  _ASSISTANT_ROLE = \"assistant\"\n",
        "  _TOOL_ROLE = \"tool\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      tokenizer: PreTrainedTokenizerBase,\n",
        "      tools: Optional[List[Dict[str, Any]]] = None,\n",
        "  ):\n",
        "\n",
        "    self._tokenizer = tokenizer\n",
        "    self._tools = tools\n",
        "    super().__init__(turn_class=HfTurn, chunk_class=HfChunk)\n",
        "\n",
        "  @property\n",
        "  def user_role(self) -> str:\n",
        "    return self._USER_ROLE\n",
        "\n",
        "  @property\n",
        "  def model_role(self) -> str:\n",
        "    return self._ASSISTANT_ROLE\n",
        "\n",
        "  @property\n",
        "  def tool_role(self) -> str:\n",
        "    return self._TOOL_ROLE\n",
        "\n",
        "  def get_state(self) -> List[HfTurn]:\n",
        "    return copy.deepcopy(self._state)\n",
        "\n",
        "  def get_state_mutable(self) -> List[HfTurn]:\n",
        "    return self._state\n",
        "\n",
        "  def get_chunk(\n",
        "      self, content: str, kind: ChunkKind = ChunkKind.CONTENT\n",
        "  ) -> HfChunk:\n",
        "    return HfChunk(content, kind=kind)\n",
        "\n",
        "  def get_prompt(self, inference: bool = False, tokenize: bool = False) -> str:\n",
        "    \"\"\"Generates the prompt string using the tokenizer's chat template.\"\"\"\n",
        "    if self._current_turn is not None:\n",
        "      raise ValueError(\"Cannot get the prompt while in the middle of a turn.\")\n",
        "\n",
        "    try:\n",
        "      return self._tokenizer.apply_chat_template(\n",
        "          [x.to_dict() for x in self._state],\n",
        "          tools=self._tools,\n",
        "          add_generation_prompt=inference,\n",
        "          tokenize=tokenize,\n",
        "      )\n",
        "    except Exception as e:\n",
        "      raise RuntimeError(f\"Error applying chat template: {e}\") from e\n"
      ],
      "metadata": {
        "id": "y9X3Wl_ivP7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HfModel(ModelInstance):\n",
        "  def __init__(self, model, tokenizer, tools, temperature=0.3, top_k=10):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.tools = tools\n",
        "    self.temperature = temperature\n",
        "    self.top_k = top_k\n",
        "\n",
        "  def query_model(self, prompt: str | base_prompt_builder.BasePromptBuilder) -> str | None:\n",
        "    if isinstance(prompt, str):\n",
        "      messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    elif isinstance(prompt, HfChatPromptBuilder):\n",
        "      messages = [x.to_dict() for x in prompt.get_state()]\n",
        "    try:\n",
        "      inputs = self.tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      tools=self.tools,\n",
        "      add_generation_prompt=True,\n",
        "      return_dict=True,\n",
        "      return_tensors=\"pt\"\n",
        "      )\n",
        "      inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "      max_tokens = 256 # Adjust as needed based on observation\n",
        "      out = self.model.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=max_tokens,\n",
        "          pad_token_id=self.tokenizer.pad_token_id, # Use pad_token_id\n",
        "          temperature=self.temperature,\n",
        "          top_k=self.top_k\n",
        "      )\n",
        "\n",
        "      input_token_len = inputs[\"input_ids\"].shape[1]\n",
        "      generated_tokens = out[0][input_token_len:]\n",
        "      generated_text = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "      return generated_text\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "7Sv7wDuT3BHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Evals\n",
        "\n",
        "We can now run the eval. For simplicity we will run it on the `scenarios` from above. The eval loop is very similar to above. The differnece is that we changed the mdoel and added an autorater call."
      ],
      "metadata": {
        "id": "Jq8GiNtO9GTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"MadeAgents/Hammer2.1-1.5b\""
      ],
      "metadata": {
        "id": "Bv2REnT20ZP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2f3b9ebafad248118b64cf23dce0a61d",
            "32741f06e5084d8798c2224efcd7c3cf",
            "5887704c80884c929e8d372089a011cb",
            "11dab0cfc62e4f6581d3780e75d7447e",
            "416a1915b7e74c47b11d03e285f6a4ae",
            "33dc3183d5dc40ef82b6f127beb287fb",
            "b5184142a28a419f9050e22242d4a933",
            "ebb4245441924896891f1632bbf6f629",
            "141064ef626c41aba3d7e078eaf4fa6f",
            "1634a1925df243928b753fab773df957",
            "656370ea54dc4dd2b4b89ffcfde3a19e",
            "9705736d66a842169404503244eded5c",
            "7f7a15d398a04e59a42be6ea9fc1fcdf",
            "eda94e4151bb4d53bfcfaf972a81eca6",
            "3507a8b9c00a41e4a807e59e7c9785a5",
            "315f57be19534156ba0b01022de1e124",
            "391cfc87c42c4cb48dab62ebb8629430",
            "474db1b9a1124c07969b50691c6bdad8",
            "e9e005a9f6504e118431a504262e9551",
            "8845ec543d5249aabb95ceb477f7f33f",
            "23d8961b88c741a8910c259971e28ff5",
            "537741f1deed45fcb8d8a4a2224b645f",
            "6a4596dca9e84673ab2c982f872fc422",
            "87db057a86c542d4a4c1a9578368a1ce",
            "f01de8ddf7b44acc810dcab31b1c871e",
            "2b242a2d6b684bb1a5b035bde30e41f3",
            "1fd1b745e97a40e49ee4d809f5fb06a3",
            "70488af18eed468091b06c207b4365ba",
            "ac439360b04c4587b35e939930379243",
            "da13d9cabfbe4af58cdad42130a093f3",
            "a01ee1256dd643db9b353b3b07ae3f57",
            "ab71243e360f4d65abd245ff88b457a9",
            "4c510ca4f59641f59c469b829083789d"
          ]
        },
        "id": "-okStUJS0ZNa",
        "outputId": "148b4976-0922-4052-9e0f-6b14e3f081c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/913 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f3b9ebafad248118b64cf23dce0a61d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9705736d66a842169404503244eded5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a4596dca9e84673ab2c982f872fc422"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_output_eval(text: str) -> datagen_prompt_builder.ParseResult:\n",
        "  if not text:\n",
        "    return datagen_prompt_builder.ParseResult(function_call=None, forward=None)\n",
        "  try:\n",
        "    output_json = json.loads(text.replace(\"```\", \"\").strip())\n",
        "    function_call = FunctionCall(name = output_json[\"name\"], args={}, raw_string=text)\n",
        "    return datagen_prompt_builder.ParseResult(function_call=function_call, forward=None)\n",
        "  except json.JSONDecodeError:\n",
        "    return datagen_prompt_builder.ParseResult(function_call=None, forward=text)"
      ],
      "metadata": {
        "id": "E_agLQ2y2x1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_eval_loop(scenario: str):\n",
        "  # Make the replier model prompt. The replier model will pretend to be the human\n",
        "  replier_pbuilder = ReplierPromptBuilder()\n",
        "  replier_pbuilder.system_turn(margin.trim_margin(f\"\"\"\\\n",
        "      |You are using a mobile app with a voice feature attached to an agent. You\n",
        "      >want to fill out a healthcare intake form which has three screens.\n",
        "      |The screens are as follows:\n",
        "      |Screen 1: Asks for first and second name, date of birth, and occupation\n",
        "      |Screen 2: Asks for marital status ({\", \".join(marital_status_options)})\n",
        "      >and sex {\", \".join(sex_options)}\n",
        "      |Screen 3: Asks for health conditions ({\", \".join(health_conditions_options)})\n",
        "      |\n",
        "      |You are given the following patient scenario:\n",
        "      |{scenario}\n",
        "      |\n",
        "      |Please talk to the agent (you should go screen by screen). First you reply\n",
        "      >to the first srceen, wait for its reply, then you reply to the second, etc.\n",
        "      |Your messages are prefaced by the `User` role, while the agent's responses\n",
        "      >are prefaced by the `Assistant` role.\n",
        "      >If the agent is able to successfully complete the task, please\n",
        "      >reply with STOP. If it made an error, reply with ERROR.\n",
        "      |Do not ask the assistant any follow-up questions.\n",
        "      |When you return your reply, do not preface it with any role, that happens\n",
        "      >automatically.\n",
        "      |NOTE: Only give a single reply at a time, do not complete the entire\n",
        "      >conversation.\n",
        "      |NOTE: Give your replies in natural language only.\n",
        "      \"\"\"))\n",
        "  # Set models\n",
        "  replier_model = AIStudioModel(api_key=API_KEY, model_name=MODEL)\n",
        "  function_calling_model = HfModel(model=model, tokenizer=tokenizer, tools=json.loads(tool2str(my_demo_tool)))\n",
        "  validation_model = AIStudioModel(api_key=API_KEY, model_name=MODEL)\n",
        "\n",
        "  # Get a scenario -> intial query\n",
        "  initial_query = replier_model.query_model(replier_pbuilder.get_prompt())\n",
        "  initial_query = initial_query.replace(\"User:\", \"\").replace(\"User\", \"\").strip()\n",
        "  # Add the initial query to the user turn\n",
        "  replier_pbuilder.user_turn(initial_query)\n",
        "\n",
        "  # Create a prompt builder to represent the agent\n",
        "  inner_hf_pb = HfChatPromptBuilder(tokenizer=tokenizer, tools=json.loads(tool2str(my_demo_tool)))\n",
        "  inner_hf_pb.begin_turn(inner_hf_pb.user_role)\n",
        "  inner_hf_pb.add_content(inner_hf_pb.get_chunk(initial_query))\n",
        "  inner_hf_pb.end_turn()\n",
        "  datagen_pbuilder = datagen_prompt_builder.DataGenerationPromptBuilder(\n",
        "    inner_prompt_builder=inner_hf_pb,\n",
        "    session=SimpleEnvironment(),\n",
        "    parse_fn=parse_output_eval,\n",
        "  )\n",
        "  # Run episode\n",
        "  try:\n",
        "    result = function_calling_episode.run_function_calling_episode(\n",
        "          fc_prompt_builder=datagen_pbuilder,\n",
        "          replier_prompt_builder=replier_pbuilder,\n",
        "          function_calling_model=function_calling_model,\n",
        "          replier_model=replier_model,\n",
        "          max_steps=6,\n",
        "    )\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return []\n",
        "\n",
        "\n",
        "  output_state = [x.to_dict() for x in result.get_state()]\n",
        "\n",
        "  validation_result = validation_model.query_model(margin.trim_margin(f\"\"\"\\\n",
        "      |You are given the following conversation between a user and an AI voice\n",
        "      >feature for filling out a healthcare intake form:\n",
        "      |{json.dumps(output_state)}\n",
        "      |\n",
        "      |If the agent correctly filled out the form, reply with YES, otherwise\n",
        "      >reply with NO.\n",
        "      |\n",
        "      |NOTE: Only reply with YES or NO.\n",
        "      \"\"\"))\n",
        "  if \"YES\" in validation_result:\n",
        "    return output_state\n",
        "  else:\n",
        "    return []\n"
      ],
      "metadata": {
        "id": "2U3C3wtV0KfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversations = []\n",
        "for scenario in scenarios:\n",
        "  conversation = run_eval_loop(scenario)\n",
        "  if conversation:\n",
        "    print(\"Done with scenario \", scenario)\n",
        "  else:\n",
        "    print(\"Failed scenario \", scenario)"
      ],
      "metadata": {
        "id": "H0-1Ppvx6TGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsOL5tUv6l80"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}